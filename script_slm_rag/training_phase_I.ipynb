{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e6f1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "import json\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "file_path = \"/content/ori_pqaa.json\"  \n",
    "try:\n",
    "    with open(file_path, \"r\") as f:\n",
    "      data = json.load(f)\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"JSON Error: {e}\")\n",
    "    with open(file_path, \"r\") as f:\n",
    "      content = f.read()\n",
    "      start = max(0, e.pos - 100)\n",
    "      end = min(len(content), e.pos + 100)\n",
    "      print(f\"Error context: {content[start:end]}\")\n",
    "\n",
    "samples = []\n",
    "for key, value in data.items():\n",
    "    context = \" \".join(value[\"CONTEXTS\"])  \n",
    "    label = 0 if value[\"final_decision\"] == \"yes\" else (1 if value[\"final_decision\"] == \"no\" else 2)\n",
    "    samples.append({\"question\": value[\"QUESTION\"], \"context\": context, \"answer\": label})\n",
    "\n",
    "dataset = Dataset.from_list(samples)\n",
    "dataset = dataset.train_test_split(test_size=0.1)  \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\")\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['question'], examples['context'], truncation=True, padding='max_length', max_length=512)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"answer\", \"labels\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\", num_labels=3)\n",
    "model.to(device)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results_biobert_colab\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    fp16=True,\n",
    "    dataloader_num_workers=2,\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=tokenized_datasets[\"train\"], eval_dataset=tokenized_datasets[\"test\"])\n",
    "trainer.train()\n",
    "trainer.save_model(\"./results_biobert_colab\")\n",
    "results = trainer.evaluate()\n",
    "print(results)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b9c6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "epochs = [1, 2, 3]\n",
    "training_loss = [0.100900, 0.057400, 0.033800]\n",
    "validation_loss = [0.091560, 0.103264, 0.141920]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, training_loss, color='#1f77b4', marker='o', label='Training Loss', linewidth=2, markersize=8)  # Xanh dương\n",
    "plt.plot(epochs, validation_loss, color='#ff7f0e', marker='s', label='Validation Loss', linewidth=2, markersize=8)  # Cam\n",
    "\n",
    "plt.title('Training vs Validation Loss', fontsize=14)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "for i, (tr, val) in enumerate(zip(training_loss, validation_loss)):\n",
    "    plt.annotate(f'{tr:.4f}', (epochs[i], training_loss[i]), textcoords=\"offset points\", xytext=(0,10), ha='center', fontsize=9)\n",
    "    plt.annotate(f'{val:.4f}', (epochs[i], validation_loss[i]), textcoords=\"offset points\", xytext=(0,10), ha='center', fontsize=9)\n",
    "\n",
    "plt.xticks(epochs)\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_results.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
